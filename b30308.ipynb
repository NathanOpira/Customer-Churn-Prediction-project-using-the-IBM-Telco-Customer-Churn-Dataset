{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b52fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries and setup.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix, classification_report)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Reproducibility.\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Path to dataset\n",
    "DATA_PATH = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c4db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training class distribution: Counter({0: 3622, 1: 1308})\n",
      "Original test class distribution: Counter({0: 1552, 1: 561})\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "# Loading dataset.\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "\n",
    "# Basic cleanup steps & target encoding.\n",
    "# Mapping target 'Churn' to binary 1/0\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "# Handling TotalCharges blanks and converting to numeric.\n",
    "# In this dataset TotalCharges may be empty strings for customers with tenure=0\n",
    "# Converting to numeric coercing errors to NaN, then fill with median.\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'].replace(' ', np.nan), errors='coerce')\n",
    "total_median = df['TotalCharges'].median()  # choosing median to be robust\n",
    "df['TotalCharges'].fillna(total_median, inplace=True)\n",
    "\n",
    "\n",
    "# Identifying features.\n",
    "target_col = 'Churn'\n",
    "# Treat object dtype (excluding customerID) as categorical / nominal.\n",
    "drop_cols = ['customerID'] if 'customerID' in df.columns else []\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols + [target_col]]\n",
    "\n",
    "# Separate numeric vs categorical\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "# Confirm numeric cols exist; if not, detect numerics automatically\n",
    "numeric_cols = [c for c in numeric_cols if c in df.columns]\n",
    "# For categorical, use object dtype columns or explicitly exclude numeric\n",
    "categorical_cols = [c for c in feature_cols if c not in numeric_cols]\n",
    "\n",
    "\n",
    "# One-Hot Encoding for nominal categorical features.\n",
    "# Use drop_first=True to reduce collinearity.\n",
    "df_encoded = pd.get_dummies(df.drop(columns=drop_cols), columns=categorical_cols, drop_first=True)\n",
    "\n",
    "\n",
    "# Feature matrix and target vector\n",
    "X = df_encoded.drop(columns=[target_col])\n",
    "y = df_encoded[target_col]\n",
    "\n",
    "# Min-Max Scaling for numeric features (its very important to do this on the full data BEFORE the split so transforms are consistent.)\n",
    "# we scaled across the whole dataset for simplicity.\n",
    "scaler = MinMaxScaler()\n",
    "# finding the scaled numeric columns names in X (they exist unchanged since get_dummies didn't touch them)\n",
    "scale_cols = [c for c in numeric_cols if c in X.columns]\n",
    "X[scale_cols] = scaler.fit_transform(X[scale_cols])\n",
    "\n",
    "\n",
    "# Train/test split (70/30) with stratification on churn.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Original training class distribution:\", Counter(y_train))\n",
    "print(\"Original test class distribution:\", Counter(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750e571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE training class distribution: Counter({0: 3622, 1: 3622})\n"
     ]
    }
   ],
   "source": [
    "#HANDLING CLASS IMBALANCE WITH SMOTE\n",
    "\n",
    "# Applying SMOTE on training data only. Keep the test set untouched.\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After SMOTE training class distribution:\", Counter(y_train_smote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f60fe2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features by Mutual Information (pre-SMOTE training set):\n",
      "tenure                                  0.076137\n",
      "Contract_Two year                       0.060981\n",
      "InternetService_Fiber optic             0.054962\n",
      "PaymentMethod_Electronic check          0.051235\n",
      "MonthlyCharges                          0.044990\n",
      "TotalCharges                            0.038035\n",
      "DeviceProtection_No internet service    0.034879\n",
      "TechSupport_No internet service         0.034649\n",
      "StreamingMovies_No internet service     0.034344\n",
      "OnlineBackup_No internet service        0.030516\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#FEATURE SELECTION USING MUTUAL INFORMATION FOR LOGISTIC REGRESSION MODELING\n",
    "\n",
    "# Computing mutual information scores on the pre-SMOTE training set.\n",
    "mi_scores = mutual_info_classif(X_train, y_train, random_state=RANDOM_STATE)\n",
    "mi_series = pd.Series(mi_scores, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# Top 10 most informative features.\n",
    "top_10_features = mi_series.head(10)\n",
    "print(\"Top 10 features by Mutual Information (pre-SMOTE training set):\")\n",
    "print(top_10_features)\n",
    "\n",
    "# For later steps we need the list (as Python list).\n",
    "top10_feature_list = top_10_features.index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION IMPLEMENTATION AND PARAMETER HYPERPARAMETER TUNING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
